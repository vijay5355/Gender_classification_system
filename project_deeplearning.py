# -*- coding: utf-8 -*-
"""PROJECT_DEEPLEARNING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KFRbZi2pjFt5dySQLykGt4gZykDv1aQX
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d hemanthsai7/solar-panel-dust-detection

"""**Firstly Importing Libraries**

"""

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
import matplotlib.pyplot as plt
import cv2

# !kaggle datasets download -d saadpd/menwomen-classification
import kagglehub

# Download latest version
path = kagglehub.dataset_download("saadpd/menwomen-classification")

print("Path to dataset files:", path)

import zipfile
zipdata = zipfile.ZipFile('/content/menwomen-classification.zip')
zipdata.extractall('/content/')
zipdata.close()

img = cv2.imread('/content/testdata/testdata/men/00000018.jpg')
img

plt.imshow(img)

img.shape

#Generators
train_ds = tf.keras.utils.image_dataset_from_directory(

    directory = '/content/traindata/traindata',
    labels = 'inferred',
    label_mode = 'int',
    batch_size = 32,
    image_size = (256,256),
    )

test_ds = tf.keras.utils.image_dataset_from_directory(
    directory = '/content/testdata/testdata',
    labels = 'inferred',
    label_mode = 'int',
    batch_size = 32,
    image_size = (256,256),
    )

#Normaliztion


def scale_down_px(image,label):

  image = tf.cast(image/255 ,tf.float32)
  return image,label

train_ds = train_ds.map(scale_down_px)
test_ds = test_ds.map(scale_down_px)

model = Sequential()

model.add(Conv2D(32,kernel_size = (3,3),padding = 'valid',activation = "relu",input_shape = (256,256,3)))
model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = 'valid'))

model.add(Conv2D(64,kernel_size = (3,3),padding = 'valid',activation = "relu"))
model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = 'valid'))

model.add(Conv2D(128,kernel_size = (3,3),padding = 'valid',activation = "relu"))
model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = 'valid'))


model.add(Flatten())

model.add(Dense(128,activation = 'relu'))
model.add(Dense(64,activation = 'relu'))
model.add(Dense(1,activation = 'sigmoid'))

model.summary()

model.compile(optimizer = 'adam' ,loss = 'binary_crossentropy',metrics = 'accuracy')

history = model.fit(train_ds , validation_data=test_ds, epochs = 10)

"""# **TRAINING AND VALIDATION ACCURACY GRAPH**"""

plt.plot(history.history['accuracy'],color = 'red',label = 'Training accuracy')
plt.plot(history.history['val_accuracy'],color = 'blue',label = 'Testing accuracy')
plt.legend()
plt.show()

"""# **TRAINING AND VALIDATION LOSS GRAPH**"""

plt.plot(history.history['loss'],color = 'red',label = 'Training Loss')
plt.plot(history.history['val_loss'],color = 'blue',label = 'Testing Loss')
plt.legend()
plt.show()

"""This is the condition of overfitting , where we have the difference between the accuracies of test and training data is about 20%.




"""

from keras.layers import BatchNormalization, Dropout

model = Sequential()

model.add(Conv2D(32,kernel_size = (3,3),padding = 'valid',activation = "relu",input_shape = (256,256,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = 'valid'))

model.add(Conv2D(64,kernel_size = (3,3),padding = 'valid',activation = "relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = 'valid'))

model.add(Conv2D(128,kernel_size = (3,3),padding = 'valid',activation = "relu"))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = 'valid'))


model.add(Flatten())

model.add(Dense(128,activation = 'relu'))
model.add(Dropout(0.1))
model.add(Dense(64,activation = 'relu'))
model.add(Dropout(0.1))
model.add(Dense(1,activation = 'sigmoid'))

model.summary()

model.compile(optimizer = 'adam' ,loss = 'binary_crossentropy',metrics = 'accuracy')

history = model.fit(train_ds , validation_data=test_ds, epochs = 10)

"""# **TRAINING AND VALIDATION ACCURACY GRAPH**"""

plt.plot(history.history['accuracy'],color = 'red',label = 'Training accuracy')
plt.plot(history.history['val_accuracy'],color = 'blue',label = 'Testing accuracy')
plt.legend()
plt.show()

"""# **TRAINING AND VALIDATION LOSS GRAPH**"""

plt.plot(history.history['loss'],color = 'red',label = 'Training Loss')
plt.plot(history.history['val_loss'],color = 'blue',label = 'Testing Loss')
plt.legend()
plt.show()

"""# **TESTING THE IMAGES**"""

test_img = cv2.imread('/content/testdata/testdata/men/00000256.jpg')
test_img

plt.imshow(test_img)

test_img.shape

test_img = cv2.resize(test_img,(256,256))
test_img

plt.imshow(test_img)

test_img.shape

test_input = test_img.reshape(1,256,256,3)

model.predict(test_input)

"""It is proved successfully that the image is of a man since the value should be nearly 0"""

test_img = cv2.imread('/photo')

plt.imshow(test_img)

test_img.shape

test_img = cv2.resize(test_img,(256,256))
test_img

plt.imshow(test_img)

test_img.shape

test_input = test_img.reshape(1,256,256,3)

model.predict(test_input)

"""Another example also proves the same thing i.e., the picture is of man."""

test_img = cv2.imread('/content/traindata/traindata/women/00000006.png')
test_img

plt.imshow(test_img)

test_img.shape

test_img = cv2.resize(test_img,(256,256))

test_img.shape

test_input = test_img.reshape(1,256,256,3)

model.predict(test_input)

"""This shows that the picture is of women as the output is 1."""



"""# **Thanks Everyone**"""